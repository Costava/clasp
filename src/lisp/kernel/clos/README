Like most CLOS implementations, Clasp's goes through some weirdness to have things work correctly with the MOP. These conceptual notes are intended to aid reading of the code, because comments can't do it all.

Of course, internals notes tend to not be updated, so it's possible the information here isn't accurate. It ought to be as of May 2019 (git commit hash 69f6eb7e6ffcbf45edbc13ad8baa66fd67b9ccc1). Hopefully you're reading a file under version control, in which case you could try looking at the history of this directory to see if there have been any major changes since now.

Booting
=======

Classes and instances
---------------------

Defined in the conventional way, basically a pointer to the class, and a "rack", the vector of slots. Plus some other crap. Defined in core/instance.h. (FYI the rack is a separate vector rather than a stretchy part of the instance so that change-class can swap it out.)

After package.lsp, hierarchy.lsp is loaded. It defines variables containing specifications for the slot definitions of important standard classes. For example,

(defparameter +method-combination-slots+
 `((name :initarg :name :accessor method-combination-name)
   (compiler :initarg :compiler :accessor method-combination-compiler)
   (options :initarg :options :accessor method-combination-options)))

These are used to describe slots before slot definitions exist as objects. Particularly, std-slot-value.lsp defines WITH-EARLY-ACCESSORS and WITH-EARLY-MAKE-INSTANCE. The former defines local macros with the slot names that expand into direct instance references. For example,

(with-early-accessors (+method-combination-slots+) (method-combination-compiler mc))

would expand to

(macrolet ((method-combination-compiler (object) `(si::instance-ref ,object ,1)))
  (method-combination-compiler mc))

which is in turn equivalent to (si::instance-ref mc 1). This allows slot values to be accessed naturally without going through all the machinery of slot-value. Of course, it only works if slot locations don't change. It should probably use flet instead of macrolet, but local function inlining isn't working.

WITH-EARLY-MAKE-INSTANCE similarly makes instances without calling generic functions, using si::allocate-raw-instance and si::instance-set.

Some of the slot definitions are a little funny. standard-class has "class-id": this is unexported and nonstandard, but basically equivalent to class-name. I believe we don't use class-name because (setf class-name) is defined to call reinitialize-instance, which is inoperative during boot.

boot.lsp actually creates the classes in hierarchy.lsp - again, directly, using core:allocate-raw-class and with-early-accessors. It does this by looking at +class-hierarchy+ in hierarchy.lsp. Some classes are in there more than once - they are redefined.

After boot.lsp all standard classes are in their final states, i.e. no further bootstrap weirdness.

Generic functions
-----------------

Instances and classes are all defined relatively straightforwardly. This is not the case for generic functions. We rely on a few things to get the system up:

 * CLHS and MOP both have "restrictions on portable programs", basically that programs cannot redefine standard functions and methods, or extend them in certain difficult ways, without meeting undefined behavior. (Unfortunately, at present, we leave this behavior really undefined - could range from "extension is silently ignored" to "crash".)
 * Defining generic functions as simple functions performing only their standard behavior, and then later using these functions as the standard methods.
 * Satiation (explained below).

The generic dispatch uses the currently new technique we have optimistically called "fastgf". Fastgf has its own section below. The algorithm is more fully described in Strandh, R. (2014). Fast generic dispatch for Common Lisp. Proceedings of ILC 2014 on 8th International Lisp Conference - ILC 14. doi:10.1145/2635648.2635654

To set the system up, everything is defined with normal functions which we then convert into generics/methods/etc.

kernel.lsp defines a few important functions, some of which are used indefinitely, and some of which are redefined later.

 * ENSURE-GENERIC-FUNCTION will be redefined. This version uses with-early-make-instance.
 * The final standard method of COMPUTE-DISCRIMINATING-FUNCTION is defined here as a non-generic function. It only seems to be called as such by set-generic-function-dispatch, also in this file.
 * (SETF GENERIC-FUNCTION-NAME) checks *clos-booted*, calls reinitialize-instance if it's so, or else (setf slot-value).
 * The final standard method of COMPUTE-APPLICABLE-METHODS is defined here as a non-generic function.
 * The function that will be used as the primary method of COMPUTE-APPLICABLE-METHODS-USING-CLASSES is defined here, but not bound as the function.
 * A non-generic PRINT-OBJECT that simply uses print-unreadable-object is defined. This will be upgraded to a method later. It's defined earlier so that if you're unlucky enough to hit a problem during boot, instances can be printed.

method.lsp defines the final definition of DEFMETHOD. It also defines the final standard method of MAKE-METHOD-LAMBDA as a function, and defines early, non-generic versions of GENERIC-FUNCTION-METHOD-CLASS and ADD-METHOD. An early version of the internal function MAKE-METHOD (no relation to the local macro - it makes a method, like make-instance) is defined here. FIND-METHOD's final standard method is here defined as a function.

The early add-method stores information in *early-methods* for use in fixup.lsp. An alist (function-name . list-of-methods).

Note that all this adds up so that until these functions are redefined, DEFMETHOD forms don't require generic function calls at any time.

combin.lsp defines various early versions of COMPUTE-EFFECTIVE-METHOD and FIND-METHOD-COMBINATION. Also it installs the DEFINE-METHOD-COMBINATION macro, and all the simple standard ones.

slotvalue.lsp starts using DEFMETHOD, and thus defining generic functions as well.

standard.lsp defines (final) methods for most of the instance creation and initialization protocol. change.lsp does CHANGE-CLASS and REINITIALIZE-INSTANCE. stdmethod.lsp defines a few methods and stuff for methods.

generic.lsp defines DEFGENERIC and a few related things like ENSURE-GENERIC-FUNCTION-USING-CLASS.

fixup.lsp is what puts the system into the final mode, redefining early functions as methods, etc. Up to this point no generic functions have been called. First, fixup converts a few critical functions into methods early - the ones needed to compute a discriminating function. Then, all existing generic functions have a "specializer profile" set up. This is part of fastgf, and is simply a sequence of Ts and NILs indicating which required arguments are currently specialized on.

With that done, we "satiate" critical generic functions. This is done in satiation.lisp. Satiation means setting up a fake call history with precomputed effective methods, for a few critical paths, namely the ones enabling discriminating functions to be computed. The full list is in satiate-standard-generic-functions. Satiation is done entirely without generic functions, using early-accessors and the primitive ungeneric functions for some things (e.g. compute-effective-method).

After satiation, add-direct-method is used to associate early methods with generic functions. Either it or method-specializers will be the first generic functions to actually be called, so you may run into problems here.

After that *early-methods* is unbound, so don't add any more methods until the final add-method is defined in a minute.

The final ENSURE-GENERIC-FUNCTION is installed next. It calls generic functions, so DEFGENERIC and DEFMETHOD after this will call generics.

Then a few things are redefined, most notably ADD-METHOD and REMOVE-METHOD, which are also immediately upgraded into methods. More stuff that should be inoffensive.

At the end of this file, CLOS is "set up" in that you should be able to manipulate generic functions with impunity. However some things like detailed PRINT-OBJECT are later.

Also note that "satiation" is done differently in the build from the final image. fixup.lsp is first loaded, which results in the process described above to get CLOS working. Then fixup.lsp is compiled. In this case the call histories and hopefully soon the discriminating functions are dumped into the fasl as described in "satiation" below, which means they don't have to be compiled (as much) as the system starts, which really helps startup time.

Operation
=========

Dispatch/fastgf
---------------

The code for fastgf is mainly in closfastgf.lsp and cmpfastgf.lsp. The latter is separate and uses bclasp for bootstrap reasons- since cleavir itself uses CLOS, recompiling a generic function in cleavir with cleavir would have unfortunate results. (But see "Interpreter", below.)

Basic dispatch technique is as follows. The discriminating function has a slow path and a fast path. We start with the fast path. The fast path is a discrimination tree, or "dtree". Each required argument position goes through a binary search based on its class stamp (a natural number each class has). Each leaf of the tree is an "outcome", which is an effective method function or something fancier that does the same thing (see below). If the search fails at any time, it goes to the slow path.

For example, if we have (defmethod foo ((x integer) y) outcome0), the stamp of FIXNUM is 7, and the stamp of BIGNUM is 8 (and integer = fixnum + bignum), we could validly have any of the following fast paths:

(slow-path)

(let ((xs (core:instance-stamp x)))
  (if (= xs 7)
      outcome0
      (slow-path)))

(let ((xs (core:instance-stamp x)))
  (if (= xs 8)
      outcome0
      (slow-path)))

(let ((xs (core:instance-stamp x)))
  (if (>= xs 7)
      (if (<= xs 8)
          outcome0
          (slow-path))
      (slow-path)))

slow-path is an abbreviation for illustration - the real function is DISPATCH-MISS. Anyway, the point is it works based on the actual class of the instance, that is the class that the instance is a direct instance of.

For a new generic function, the "fast path" is always the first one, i.e. immediately goes to the slow path. The slow path does roughly what MOP suggests, that is, first it calls compute-applicable-methods-using-classes, and if that returns a second value of NIL it calls compute-applicable-methods. Then it uses the applicable methods to compute an effective method, and calls that.

If c-a-m-u-c returns a second value of T, the call is additionally "memoized". The list of classes of the required arguments is stored, along with the "outcome" (see below), in the generic function's "call history". The discriminating function of the generic function is set to be invalidated-dispatch-function, which is just one particular function.

When c-a-m-u-c returns a second value of NIL, meaning for standard dispatch that there is a relevant eql-specialize method, the call can still be memoized in certain circumstances. First, the generic function must be a direct instance of standard-generic-function; this ensures that there are no custom methods on c-a-m-u-c, c-a-m, or anything. Second, any arguments in an eql-specialized position must match an eql specializer. To understand what this means and why this restriction is in place, consider (defmethod foo ((x symbol))) (defmethod foo ((x (eql 'x)))). If foo is called with, say, 'y, the argument does not match an eql specializer. If the call was memoized, it would be on the symbol class. Then, if foo was called later with 'x, the fast path would take it to the symbol outcome inappropriately. So instead, we only memoize the latter call (which is probably more common anyway) and leave the slow path for the former.

This situation could be improved by essentially memoizing multiple, mostly fictitious calls in the former case, to ensure all the eql specializers are covered. At this time I believe this is more trouble than its worth.

Anyway, being invalidated, the next time the gf is called control is passed to invalidated-dispatch-function. invalidated-dispatch-function sets the discriminating function to be the result of calculate-fastgf-dispatch-function, which is basically a compute-discriminating-function method (though the actual method just sets to invalidated-dispatch-function). calculate-fastgf-dispatch-function builds a fast path based on the call history. For example, for the above function FOO, it would compute the first if there was no call history, the second if the call history was one call with a fixnum, the third if the call history was one call with a bignum, and the last if the call history had both calls.

In short, the discriminating function is a static tree of class tests as you'd do without CLOS, but with only classes from actual arguments of previous calls rather than all possible argument combinations (which can grow combinatorically), and with some extra stuff so that you can define new methods and redefine classes yada yada.

That cache invalidation is really the tricky bit. When methods are added or removed, or the gf reinitialized, or classes redefined, or whatever, relevant call history entries are removed and the gf set to invalidated-dispatch-function. New calls with relevant arguments will hit the slow path, which will then reinstall a fixed fast path.

Because of how all this works, compute-discriminating-function doesn't actually do much computing. This is perfectly conformant of course. Users can define compute-discriminating-function methods and bypass fastgf entirely. Note that compute-discriminating-function is called only where it has to be, e.g. in add-method, or reinitialization of a gf - not by fastgf itself, which uses invalidated-dispatch-function more directly.

Miscellany note: no-applicable-method is not memoized, because it's easy to pick off and not considered desirable- basically just clogging up the call history with crap. no-required-method is though, because it's a bit less trivial.

Outcomes
--------

In CLOS, the behavior of a generic function with whatever particular arguments is an "effective method". The effective method is, as described by CLOS, computed by the COMPUTE-EFFECTIVE-METHOD function. For optimization purposes, we deal with effective methods through special structure instances called "outcomes". Several types exist, corresponding to common effective methods.

Those common effective methods are as follows:
 * accessors (readers and writers)
 * "leaf" methods (methods that do not refer to their next-methods, as by call-next-method or next-method-p)
 * no-required-method or no-applicable-methods (pseudo)

To do any optimization we essentially need the effective method form to consist of (call-method #<some-method> ...). This some-method is referred to as "the method" below.

Effective methods consisting of a call to a standard slot reader or writer method are represented by optimized-slot-{reader,writer} instances. The outcome object contains the slot location along with some other things for debugging. It will be compiled into an inline instance reference, e.g. INSTANCE-REF which is specially compiled (i.e. not a function call). For the reader there is additionally a boundedness check. "standard slot reader or writer" means that there is no possibility of a slot-value-using-class or (setf slot-value-using-class) method imposing other behavior - see static-gfs/README and static-gfs/svuc.lisp for a potential way to optimize even when there is customization. Note that we have to use the direct classes of arguments for all of this, not just the classes the accessor methods are specialized on, because slot locations can change with ineritance.

"Leaf" methods are recognized by the standard method on MAKE-METHOD-LAMBDA. The body is analyzed for use of call-next-method and next-method-p, and if they're not present the method is a leaf. If the method called in an effective method is a leaf, the method-function is just called as an effective method. The outcomes used are effective-method-outcomes.

If a leaf method has all required arguments, and few enough that they can fit in registers (I'm working on abating this condition), the standard MAKE-METHOD-LAMBDA will additionally attach a "fast method function" to the method object. This is basically the method as a simple function, e.g. for (defmethod foo ((x integer)) (1+ x)) the fast method function is just (lambda (x) (1+ x)). This has the advantage of being called with just arguments, rather than a list of arguments and list of next-methods like a usual method-function. This is through the fast-method-call outcome.

If there are no applicable methods, the outcome is not memoized (because it's probably just clutter). It is still computed, and consists of a effective-method-outcome that just calls NO-APPLICABLE-METHOD as per the standard.

If there is a lack of required methods - i.e. the method combination has some required method group, like PRIMARY in the standard combination, and it is found that no applicable methods are in this group - the outcome is memoized, just for lack of effort. It consists of a effective-method-outcome that calls NO-REQUIRED-METHOD.

The general case of an effective method that doesn't fit any of the above is represented by an effective-method-outcome. The object contains an effective method function and a list of applicable methods. The applicable methods slot is used so that if two call history entries have the same applicable methods, they can use the same effective method outcome, thus saving a bit of time and space. This can also make the dispatch tree more compact - if stamps 347-350 result in the same outcome, we can just test (<= 347 stamp 350) instead of doing four (= ...) tests.

Note that this caching relies on the assumpion that COMPUTE-EFFECTIVE-METHOD is basically well behaved, in that if called with EQUAL method lists (and no redefinitions of the gf, etc. inbetween) it will return morally identical results. Note when I say "morally", it's because an effective method is a behavior, and the intuitive equivalence relation of behaviors is uncomputable. So if a programmer defines a COMPUTE-EFFECTIVE-METHOD method that use randomness or depend on the time of day or whatnot, fastgf won't pick it up. Given how often COMPUTE-EFFECTIVE-METHOD is specialized at all, let alone in such a pathological way, I think this is a reasonable condition to impose. We should document this better, though (FIXME).

Currently all functions, as well as effective method outcomes, go through basically the same codegen path, so they have the same protocol- they take two arguments, first a vaslist of the gf arguments, then the next-methods. The next-methods are always NIL. FIXME.

Outcomes are computed by compute-outcome.

If all the outcomes in a call-history are NOT effective-method- or function- outcomes, the discriminating function doesn't need to produce a list of the arguments. This helps efficiency.

Satiation Interface
-------------------

The major downside of fastgf is that compiling the discriminating functions takes time, and this can occur at time, leading to inconsistencies in timing and stuff. And since for various reasons Clasp has an especially slow compiler, we really feel this pain. The way we soothe this is "satiation" - installing call histories into generic functions without actually compiling them. We also use satiation to boot up the system as described above, but we can use it for optimization too. (All the code is in satiation.lsp.)

As an example of the importance of this satiation, consider INITIALIZE-INSTANCE. Say it starts out with an empty call history. Then it's called to initialize something - a cleavir-ast:progn-ast object, say. This results in a dispatch miss followed by a discriminating function compilation. If it's then called with a cleavir-ast:car-ast object, there's another dispatch-miss and another compilation. Etc. etc., so every AST class results in another compile essentially the first time you try to use Cleavir. This causes a noticeable time lag, and the worse part is it's basically because fastgf is overeager - if it accumulated a call history of a few dozen classes, it could just compile once and be done.

Instead we start it out with a fake call history so that once it's compiled once, we're golden.

The interface to this is the CLOS:SATIATE function. The interface is described on the wiki but also here:

You call (CLOS:SATIATE generic-function ...lists of specializer designators...). A "specializer designator" is either a specializer, a symbol (the name of a class), or a list (eql <object>) representing an eql specializer for that (unevaluated) object. This adds to any existing call history by adding entries for the given specializer lists.

For the initialize-instance example, we would just do (clos:satiate #'initialize-instance '(cleavir-ast:progn-ast) '(cleavir-ast:car-ast) ...) and presto. (Obviously you only need specializers for the required parameters.)

As a bonus, if you have a literal (CLOS:SATIATE ...) form, a compiler macro will try to compute the call history at compile time, provided the generic function and all appropriate methods exist.

As a further extension that I'm still working on, the source of the discriminating function will appear in the compiler macroexpansion of CLOS:SATIATE, so that it isn't computed at load time at all. This requires coordination between the compiler and loader, because the stamp numbers have to appear literally in the code, meaning they have to be the same at compile-time and load-time. This may not be practical for non-internal code.

Interpreter
-----------

Another way of fighting the compiler is the "dtree interpreter". This is a C++ function living in funcallableInstance.cc that can serve as as funcallable instance function. It uses the same call history, outcomes, etc. as the fastgf algorithms described above, but it interprets the dtree rather than compiling a new discriminator when necessary. This can save time as compilation is avoided, at the expense of the discrimination itself being rather slower. By default, we use the interpreter for functions until an arbitrary number (1024 at the moment) of calls are performed, at which point the compiler comes into play.

An interesting consequence of having the interpreter is that we could use the cleavir compiler for compiling discriminating functions. What we'd do is, when we hit a dispatch-miss, first put the interpreter into place, then compile the new discriminator. If the compilation recursively calls the function we're trying to compile a discriminator for, it will just use the interpreter and there will be no problem.

Static GFs (make-instance "ctors")
----------------------------------

See static-gfs/README.

Modification
============

Proceed with caution.

There are informational debug macros. mlog is defined in hierarchy.lsp and is good if you have a problem before generic function calls. Various places use mlog, which just expands into nothing normally. However, mlog puts out a lot of output, and once generic functions start being called this output will be too voluminous for humans to make serious use of.

At the top of closfastgf is a thing putting :debug-fastgf in *features*. This is how you debug problems with generic function calls. There's a lot of output so it dumps it into a file in /tmp based on the PID. What it essentially does is log the dispatch miss "slow path" in which a generic function has to compute a new effective method etc.

If a function should be satiated but isn't, this will be represented in this log as infinite recursive calls, like "Dispatch miss for <whatever> ... Dispatch miss for <whatever> ..." This indicates that the dispatch miss code is itself trying to call the function. The solution is probably to throw the function into satiation.lsp. Of course maybe you're reading this in the future when infinite recursion doesn't cause a hard crash ha ha fucking ha

Problems
========

It should basically work. There are a few conformance issues though, especially with the more obscure MOP use.

 * As mentioned, we let illegal modifications to standard functionality go through with nary a peep.
 * Method functions take a va-list rather than a list. Custom methods could run into problems there.
